# Speech to Text

Choosing the best Speech-to-Text API for your product can be challenging. You’ll need to compare accuracy, features, support options, documentation, security, and more.

But if you’re looking to use an API for a small project or for a trial run, many of today’s Speech-to-Text APIs have a free tier. This means that the API is free for anyone to use up to a certain volume per month or per year.

Let’s look at three of the most popular Speech-to-Text APIs with a free tier: Google, AssemblyAI, and AWS Transcribe.

[Google](https://cloud.google.com/speech-to-text)

[AssemblyAI](https://www.assemblyai.com/)

[AWS Transcribe](https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsf.Free%20Tier%20Categories=*all)

##### Open Source Speech-to-Text Transcription Engines

An alternative to APIs, open source Speech-to-Text libraries are completely free--with no limits on use. Some developers also see data security as a plus, since your data doesn’t have to be sent to a third party or to the cloud.

[DeepSpeech](https://github.com/mozilla/DeepSpeech)
DeepSpeech is an open source embedded Speech-to-Text engine designed to run in real-time on a range of devices, from high powered GPUs to a Raspberry Pi 4. The DeepSpeech library uses end-to-end model architecture pioneered by Baidu.

DeepSpeech also has decent out-of-the-box accuracy for an open source option, and is easy to fine tune and train on your own data.

[Kaldi](https://github.com/kaldi-asr/kaldi)
Kaldi is a speech recognition toolkit that has been widely popular in the research community for many years.

Like DeepSpeech, Kaldi has good out-of-the-box accuracy and supports the ability to train your own models. It’s also been thoroughly tested--a lot of companies currently use Kaldi in production and have used it for a while--making more developers confident in its application.

[Wav2Letter](https://github.com/flashlight/wav2letter)

Wav2Letter is Facebook AI Research’s Automatic Speech Recognition (ASR) Toolkit, also written in C++, and using the ArrayFire tensor library.

Like DeepSpeech, Wav2Letter is decently accurate for an open source library and is easy to work with on a small project.

[SpeechBrain](https://github.com/speechbrain/speechbrain)
SpeechBrain is a PyTorch-based transcription toolkit. The platform releases open implementations of popular research works and offers a tight integration with HuggingFace for easy access.

Overall, the platform is well-defined and constantly updated, making it a straightforward tool for training and finetuning.

[Coqui](https://github.com/coqui-ai/STT)
Coqui is our final deep learning toolkit for Speech-to-Text transcription. Coqui is used in over twenty languages for projects and also offers a variety of essential inference and productionization features.

The platform also releases custom trained models and has bindings for various programming languages for easier deployment.

#### Some of the other popular ones are below:-

[IBM](https://cloud.ibm.com/docs/speech-to-text)

[Azure](https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/)